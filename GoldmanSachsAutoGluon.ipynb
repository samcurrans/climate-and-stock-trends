{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoldmanSachsAutoGluon.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvbzilEQcQO14/m60VDXlw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nH2KD_DyTywn","executionInfo":{"status":"ok","timestamp":1634441659465,"user_tz":300,"elapsed":60376,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"36bf358d-1612-4ac6-8370-80e047914a38"},"source":["from google.colab import drive\n","drive.mount('/content/drive/') "],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"UmAKvEcCULoa","executionInfo":{"status":"ok","timestamp":1634442903945,"user_tz":300,"elapsed":103724,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["import pandas as pd\n","\n","environmental_data_atlas = pd.read_csv('/content/drive/Shared drives/Datathon/DATA_ATLAS.csv')\n","stock_company_profile = pd.read_csv('/content/drive/Shared drives/Datathon/STOCK_COMPANY_PROFILE.csv')\n","stock_history = pd.read_csv('/content/drive/Shared drives/Datathon/STOCK_HISTORY.csv')\n","stock_symbols = pd.read_csv('/content/drive/Shared drives/Datathon/STOCK_SYMBOLS.csv')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"infT-t3sUm3k","executionInfo":{"status":"ok","timestamp":1634442903946,"user_tz":300,"elapsed":14,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["def year_avg_close_price(company, year):\n","  df = stock_history[stock_history['SYMBOL'] == company]\n","  df = df[df['DATE'].str.contains(str(year))]\n","  return df['ADJCLOSE'].mean()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEyL1BNMUnYP","executionInfo":{"status":"ok","timestamp":1634442903946,"user_tz":300,"elapsed":13,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["def year_avg_volume(company, year):\n","  df = stock_history[stock_history['SYMBOL'] == company]\n","  df = df[df['DATE'].str.contains(str(year))]\n","  return df['VOLUME'].mean()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVbRGj2lUspq","executionInfo":{"status":"ok","timestamp":1634442903947,"user_tz":300,"elapsed":13,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["def average_environmental_data(year):\n","  indicators = environmental_data_atlas['Indicator'].unique().tolist()\n","  val_list = []\n","  for indicator in indicators:\n","    df = environmental_data_atlas[environmental_data_atlas['Year'] == year]\n","    val = df[environmental_data_atlas['Indicator'] == indicator]['Value'].sum()\n","    val_list.append(val)\n","  return val_list"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"N7JoNCE7UtVA"},"source":["x_vector = []\n","df = stock_history[stock_history['SYMBOL'] == 'AAPL']\n","earliest_stock = df['DATE'].min()\n","earliest_stock = earliest_stock[:4]\n","latest_stock = df['DATE'].max()\n","latest_stock = latest_stock[:4] if int(latest_stock[:4]) <= 2019 else 2019\n","for i in range(int(earliest_stock), int(latest_stock) + 1):\n","  temp = [i, year_avg_close_price('AAPL', i), year_avg_volume('AAPL', i)] + average_environmental_data(i)\n","  x_vector.append(temp)\n","\n","# labels\n","y_vector = []\n","for i in range(int(earliest_stock), int(latest_stock) + 1):\n","  y_vector.append(year_avg_close_price('AAPL', i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxPMY1wqU0W-","executionInfo":{"status":"ok","timestamp":1634444073610,"user_tz":300,"elapsed":187,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x_vector, y_vector, shuffle=False)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"w0p4gne7U44G","executionInfo":{"status":"ok","timestamp":1634444075192,"user_tz":300,"elapsed":203,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["# add columns to x_train and x_test\n","column_names = [' ', 'AVGYearlyClose']\n","for i in range(len(x_vector[0]) - 2):\n","  column_names.append(' ')\n","\n","xtest_df = pd.DataFrame(x_test, columns=column_names)\n","xtrain_df = pd.DataFrame(x_train, columns=column_names)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"vs5X_vfcU3aV","executionInfo":{"status":"ok","timestamp":1634444077988,"user_tz":300,"elapsed":199,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}}},"source":["xtest_df.to_csv(\"/content/drive/Shared drives/Datathon/autogluon_x_test.csv\")\n","xtrain_df.to_csv(\"/content/drive/Shared drives/Datathon/autogluon_x_train.csv\")"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"khjWLUMRdFov","executionInfo":{"status":"ok","timestamp":1634444081158,"user_tz":300,"elapsed":216,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"96e6f6f5-9653-4b55-f985-873e9a22e54f"},"source":["test = pd.read_csv('/content/drive/Shared drives/Datathon/autogluon_x_train.csv')\n","test.head()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th></th>\n","      <th>AVGYearlyClose</th>\n","      <th>.1</th>\n","      <th>.2</th>\n","      <th>.3</th>\n","      <th>.4</th>\n","      <th>.5</th>\n","      <th>.6</th>\n","      <th>.7</th>\n","      <th>.8</th>\n","      <th>.9</th>\n","      <th>.10</th>\n","      <th>.11</th>\n","      <th>.12</th>\n","      <th>.13</th>\n","      <th>.14</th>\n","      <th>.15</th>\n","      <th>.16</th>\n","      <th>.17</th>\n","      <th>.18</th>\n","      <th>.19</th>\n","      <th>.20</th>\n","      <th>.21</th>\n","      <th>.22</th>\n","      <th>.23</th>\n","      <th>.24</th>\n","      <th>.25</th>\n","      <th>.26</th>\n","      <th>.27</th>\n","      <th>.28</th>\n","      <th>.29</th>\n","      <th>.30</th>\n","      <th>.31</th>\n","      <th>.32</th>\n","      <th>.33</th>\n","      <th>.34</th>\n","      <th>.35</th>\n","      <th>.36</th>\n","      <th>.37</th>\n","      <th>.38</th>\n","      <th>.39</th>\n","      <th>.40</th>\n","      <th>.41</th>\n","      <th>.42</th>\n","      <th>.43</th>\n","      <th>.44</th>\n","      <th>.45</th>\n","      <th>.46</th>\n","      <th>.47</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1980</td>\n","      <td>0.107222</td>\n","      <td>1.034501e+08</td>\n","      <td>18091.80037</td>\n","      <td>1208.74617</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4120.71176</td>\n","      <td>254.81663</td>\n","      <td>3181.09850</td>\n","      <td>2723.16759</td>\n","      <td>1285.18072</td>\n","      <td>3218.61769</td>\n","      <td>589.60718</td>\n","      <td>7551732.155</td>\n","      <td>1977.64737</td>\n","      <td>9547300.083</td>\n","      <td>11820.10797</td>\n","      <td>2554164.509</td>\n","      <td>977.87869</td>\n","      <td>3.071149e+06</td>\n","      <td>9966.76698</td>\n","      <td>1.568752e+06</td>\n","      <td>12254.43371</td>\n","      <td>5.991702e+06</td>\n","      <td>1.778504e+06</td>\n","      <td>2.704464e+06</td>\n","      <td>190644.57852</td>\n","      <td>4.925495e+06</td>\n","      <td>0.0</td>\n","      <td>3583001.0</td>\n","      <td>491804.0</td>\n","      <td>84346.0</td>\n","      <td>79733.0</td>\n","      <td>104245.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1981</td>\n","      <td>0.085626</td>\n","      <td>3.252756e+07</td>\n","      <td>17787.48137</td>\n","      <td>1134.41685</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4152.68251</td>\n","      <td>243.63632</td>\n","      <td>3255.65835</td>\n","      <td>2715.75154</td>\n","      <td>1277.78739</td>\n","      <td>3271.11069</td>\n","      <td>578.42577</td>\n","      <td>7498272.234</td>\n","      <td>1976.44079</td>\n","      <td>9132716.338</td>\n","      <td>11859.32974</td>\n","      <td>2599209.937</td>\n","      <td>1052.26974</td>\n","      <td>3.026422e+06</td>\n","      <td>9960.17790</td>\n","      <td>1.521332e+06</td>\n","      <td>12311.12862</td>\n","      <td>5.851793e+06</td>\n","      <td>1.727046e+06</td>\n","      <td>2.608747e+06</td>\n","      <td>190406.15223</td>\n","      <td>4.472236e+06</td>\n","      <td>0.0</td>\n","      <td>3496746.0</td>\n","      <td>491038.0</td>\n","      <td>85016.0</td>\n","      <td>58246.0</td>\n","      <td>95737.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1982</td>\n","      <td>0.067423</td>\n","      <td>8.444667e+07</td>\n","      <td>17615.40333</td>\n","      <td>1105.34378</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4096.73010</td>\n","      <td>237.74315</td>\n","      <td>3329.35908</td>\n","      <td>2647.19429</td>\n","      <td>1261.85695</td>\n","      <td>3293.67046</td>\n","      <td>568.63327</td>\n","      <td>7670003.584</td>\n","      <td>2058.19139</td>\n","      <td>8953865.159</td>\n","      <td>11795.81588</td>\n","      <td>2548576.001</td>\n","      <td>1045.57262</td>\n","      <td>3.069972e+06</td>\n","      <td>9915.27366</td>\n","      <td>1.597245e+06</td>\n","      <td>12316.97682</td>\n","      <td>6.269163e+06</td>\n","      <td>1.762952e+06</td>\n","      <td>2.778074e+06</td>\n","      <td>192603.16155</td>\n","      <td>6.095739e+06</td>\n","      <td>0.0</td>\n","      <td>3470982.0</td>\n","      <td>465682.0</td>\n","      <td>86407.0</td>\n","      <td>58115.0</td>\n","      <td>85814.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1983</td>\n","      <td>0.131972</td>\n","      <td>1.759408e+08</td>\n","      <td>17777.75733</td>\n","      <td>1080.44134</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4140.55462</td>\n","      <td>238.43865</td>\n","      <td>3398.21203</td>\n","      <td>2603.60537</td>\n","      <td>1217.94960</td>\n","      <td>3286.09157</td>\n","      <td>593.46652</td>\n","      <td>7926593.963</td>\n","      <td>2135.02805</td>\n","      <td>8906376.642</td>\n","      <td>11715.98979</td>\n","      <td>2587578.213</td>\n","      <td>1099.51030</td>\n","      <td>3.061073e+06</td>\n","      <td>9794.18920</td>\n","      <td>1.612970e+06</td>\n","      <td>12256.46280</td>\n","      <td>6.120151e+06</td>\n","      <td>1.793234e+06</td>\n","      <td>2.753106e+06</td>\n","      <td>195212.48911</td>\n","      <td>5.635440e+06</td>\n","      <td>0.0</td>\n","      <td>3516130.0</td>\n","      <td>460276.0</td>\n","      <td>89872.0</td>\n","      <td>52269.0</td>\n","      <td>83353.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1984</td>\n","      <td>0.094400</td>\n","      <td>1.659250e+08</td>\n","      <td>18388.17896</td>\n","      <td>1117.83456</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4252.27703</td>\n","      <td>233.25241</td>\n","      <td>3439.16864</td>\n","      <td>2579.15563</td>\n","      <td>1248.28421</td>\n","      <td>3267.00953</td>\n","      <td>563.29662</td>\n","      <td>8283522.397</td>\n","      <td>2230.03724</td>\n","      <td>8953451.622</td>\n","      <td>11557.53199</td>\n","      <td>2801881.360</td>\n","      <td>1191.28291</td>\n","      <td>3.033687e+06</td>\n","      <td>9790.46621</td>\n","      <td>1.601254e+06</td>\n","      <td>12318.89175</td>\n","      <td>5.966796e+06</td>\n","      <td>1.829739e+06</td>\n","      <td>2.667446e+06</td>\n","      <td>199030.93124</td>\n","      <td>4.237173e+06</td>\n","      <td>0.0</td>\n","      <td>3649042.0</td>\n","      <td>497785.0</td>\n","      <td>93603.0</td>\n","      <td>45179.0</td>\n","      <td>83882.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0        AVGYearlyClose            .1  ...       .44   .45   .46   .47\n","0           0  1980        0.107222  1.034501e+08  ...  104245.0   0.0   0.0   0.0\n","1           1  1981        0.085626  3.252756e+07  ...   95737.0   0.0   0.0   0.0\n","2           2  1982        0.067423  8.444667e+07  ...   85814.0   0.0   0.0   0.0\n","3           3  1983        0.131972  1.759408e+08  ...   83353.0   0.0   0.0   0.0\n","4           4  1984        0.094400  1.659250e+08  ...   83882.0   0.0   0.0   0.0\n","\n","[5 rows x 50 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfvaqoOrZ5sk","executionInfo":{"status":"ok","timestamp":1634444193485,"user_tz":300,"elapsed":9186,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"cd3bac04-c7aa-413d-fa8b-7209e3e0f726"},"source":["from autogluon.tabular import TabularPredictor\n","predictor = TabularPredictor(label='AVGYearlyClose', problem_type='regression').fit(train_data='/content/drive/Shared drives/Datathon/autogluon_x_train.csv')\n","predictions = predictor.predict('/content/drive/Shared drives/Datathon/autogluon_x_test.csv')"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20211017_041629/\"\n","Loaded data from: /content/drive/Shared drives/Datathon/autogluon_x_train.csv | Columns = 50 / 50 | Rows = 30 -> 30\n","Beginning AutoGluon training ...\n","AutoGluon will save models to \"AutogluonModels/ag-20211017_041629/\"\n","AutoGluon Version:  0.3.1\n","Train Data Rows:    30\n","Train Data Columns: 49\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    10972.02 MB\n","\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tUseless Original Features (Count: 7): [' .10', ' .11', ' .12', ' .13', ' .14', ' .15', ' .16']\n","\t\tThese features carry no predictive signal and should be manually investigated.\n","\t\tThis is typically a feature which has the same value for all rows.\n","\t\tThese features do not need to be present at inference time.\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 40 | [' .1', ' .2', ' .3', ' .4', ' .5', ...]\n","\t\t('int', [])   :  2 | ['Unnamed: 0', ' ']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', []) : 40 | [' .1', ' .2', ' .3', ' .4', ' .5', ...]\n","\t\t('int', [])   :  2 | ['Unnamed: 0', ' ']\n","\t0.1s = Fit runtime\n","\t42 features in original data used to generate 42 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.15s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tTo change this, specify the eval_metric argument of fit()\n","Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 24, Val Rows: 6\n","Fitting 11 L1 models ...\n","Fitting model: KNeighborsUnif ...\n","\t-0.9312\t = Validation score   (root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: KNeighborsDist ...\n","\t-0.655\t = Validation score   (root_mean_squared_error)\n","\t0.01s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: LightGBMXT ...\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t-1.6816\t = Validation score   (root_mean_squared_error)\n","\t0.19s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: LightGBM ...\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","\t-1.6816\t = Validation score   (root_mean_squared_error)\n","\t0.16s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: RandomForestMSE ...\n","\t-0.5031\t = Validation score   (root_mean_squared_error)\n","\t0.54s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: CatBoost ...\n","\t-0.3531\t = Validation score   (root_mean_squared_error)\n","\t0.44s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: ExtraTreesMSE ...\n","\t-0.5017\t = Validation score   (root_mean_squared_error)\n","\t0.55s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitting model: NeuralNetFastAI ...\n","No improvement since epoch 0: early stopping\n","\t-1.6614\t = Validation score   (root_mean_squared_error)\n","\t0.58s\t = Training   runtime\n","\t0.03s\t = Validation runtime\n","Fitting model: XGBoost ...\n","\t-0.3606\t = Validation score   (root_mean_squared_error)\n","\t0.18s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: NeuralNetMXNet ...\n","\t-0.4455\t = Validation score   (root_mean_squared_error)\n","\t1.65s\t = Training   runtime\n","\t0.15s\t = Validation runtime\n","Fitting model: LightGBMLarge ...\n","/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[1000]\ttrain_set's rmse: 0.0181395\tvalid_set's rmse: 0.763973\n","[2000]\ttrain_set's rmse: 0.000699826\tvalid_set's rmse: 0.758573\n","[3000]\ttrain_set's rmse: 3.07312e-05\tvalid_set's rmse: 0.758282\n","[4000]\ttrain_set's rmse: 2.02959e-06\tvalid_set's rmse: 0.758263\n","[5000]\ttrain_set's rmse: 1.48576e-07\tvalid_set's rmse: 0.758262\n","[6000]\ttrain_set's rmse: 1.38725e-08\tvalid_set's rmse: 0.758262\n","[7000]\ttrain_set's rmse: 1.26527e-09\tvalid_set's rmse: 0.758262\n","[8000]\ttrain_set's rmse: 1.15965e-10\tvalid_set's rmse: 0.758262\n","[9000]\ttrain_set's rmse: 1.08724e-11\tvalid_set's rmse: 0.758262\n","[10000]\ttrain_set's rmse: 1.03314e-12\tvalid_set's rmse: 0.758262\n"]},{"output_type":"stream","name":"stderr","text":["\t-0.7583\t = Validation score   (root_mean_squared_error)\n","\t2.22s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ...\n","\t-0.2124\t = Validation score   (root_mean_squared_error)\n","\t0.31s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 8.96s ...\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211017_041629/\")\n","Loaded data from: /content/drive/Shared drives/Datathon/autogluon_x_test.csv | Columns = 50 / 50 | Rows = 10 -> 10\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdJwOCJDeVOW","executionInfo":{"status":"ok","timestamp":1634444883468,"user_tz":300,"elapsed":1048,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"dda3de0a-4938-4ea1-c97d-9c9cc6955053"},"source":["from autogluon.tabular import TabularDataset\n","print(predictor.leaderboard(TabularDataset('/content/drive/Shared drives/Datathon/autogluon_x_test.csv')))"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Loaded data from: /content/drive/Shared drives/Datathon/autogluon_x_test.csv | Columns = 50 / 50 | Rows = 10 -> 10\n"]},{"output_type":"stream","name":"stdout","text":["                  model  score_test  score_val  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0         ExtraTreesMSE  -27.128242  -0.501656        0.109473       0.102987  0.548641                 0.109473                0.102987           0.548641            1       True          7\n","1       RandomForestMSE  -27.255699  -0.503076        0.109509       0.103064  0.544385                 0.109509                0.103064           0.544385            1       True          5\n","2        NeuralNetMXNet  -27.767720  -0.445544        0.166478       0.153837  1.645616                 0.166478                0.153837           1.645616            1       True         10\n","3              CatBoost  -28.204631  -0.353104        0.003428       0.004560  0.439121                 0.003428                0.004560           0.439121            1       True          6\n","4         LightGBMLarge  -28.282731  -0.758262        0.092877       0.005596  2.218272                 0.092877                0.005596           2.218272            1       True         11\n","5   WeightedEnsemble_L2  -28.545271  -0.212364        0.025156       0.009298  0.924510                 0.003310                0.000669           0.306253            2       True         12\n","6              LightGBM  -28.734005  -1.681617        0.004826       0.003209  0.162501                 0.004826                0.003209           0.162501            1       True          4\n","7            LightGBMXT  -28.734005  -1.681617        0.010261       0.007471  0.192050                 0.010261                0.007471           0.192050            1       True          3\n","8       NeuralNetFastAI  -28.790549  -1.661388        0.033382       0.032956  0.581773                 0.033382                0.032956           0.581773            1       True          8\n","9               XGBoost  -28.913243  -0.360566        0.018419       0.004069  0.179136                 0.018419                0.004069           0.179136            1       True          9\n","10       KNeighborsDist  -28.965087  -0.654981        0.103370       0.103451  0.012369                 0.103370                0.103451           0.012369            1       True          2\n","11       KNeighborsUnif  -28.969043  -0.931232        0.102689       0.106665  0.013603                 0.102689                0.106665           0.013603            1       True          1\n","                  model  score_test  ...  can_infer  fit_order\n","0         ExtraTreesMSE  -27.128242  ...       True          7\n","1       RandomForestMSE  -27.255699  ...       True          5\n","2        NeuralNetMXNet  -27.767720  ...       True         10\n","3              CatBoost  -28.204631  ...       True          6\n","4         LightGBMLarge  -28.282731  ...       True         11\n","5   WeightedEnsemble_L2  -28.545271  ...       True         12\n","6              LightGBM  -28.734005  ...       True          4\n","7            LightGBMXT  -28.734005  ...       True          3\n","8       NeuralNetFastAI  -28.790549  ...       True          8\n","9               XGBoost  -28.913243  ...       True          9\n","10       KNeighborsDist  -28.965087  ...       True          2\n","11       KNeighborsUnif  -28.969043  ...       True          1\n","\n","[12 rows x 12 columns]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IO3oljmIhVGn","executionInfo":{"status":"ok","timestamp":1634445320533,"user_tz":300,"elapsed":211,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"9018a242-6fbb-4ada-ad91-4e0e1c75cb72"},"source":["predictor.evaluate('/content/drive/Shared drives/Datathon/autogluon_x_test.csv')"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["Loaded data from: /content/drive/Shared drives/Datathon/autogluon_x_test.csv | Columns = 50 / 50 | Rows = 10 -> 10\n","Evaluation: root_mean_squared_error on test data: -28.545271378576018\n","\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n","Evaluations on test data:\n","{\n","    \"root_mean_squared_error\": -28.545271378576018,\n","    \"mean_squared_error\": -814.8325180765512,\n","    \"mean_absolute_error\": -24.662623471505082,\n","    \"r2\": -3.2774440072294606,\n","    \"pearsonr\": -0.8825873370730156,\n","    \"median_absolute_error\": -21.759444972967504\n","}\n"]},{"output_type":"execute_result","data":{"text/plain":["{'mean_absolute_error': -24.662623471505082,\n"," 'mean_squared_error': -814.8325180765512,\n"," 'median_absolute_error': -21.759444972967504,\n"," 'pearsonr': -0.8825873370730156,\n"," 'r2': -3.2774440072294606,\n"," 'root_mean_squared_error': -28.545271378576018}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7AejQlD0jk49","executionInfo":{"status":"ok","timestamp":1634445723550,"user_tz":300,"elapsed":225,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"06964e20-25b8-4929-b865-b7c11fd4dfb8"},"source":["predictor.predict('/content/drive/Shared drives/Datathon/autogluon_x_test.csv')"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Loaded data from: /content/drive/Shared drives/Datathon/autogluon_x_test.csv | Columns = 50 / 50 | Rows = 10 -> 10\n"]},{"output_type":"execute_result","data":{"text/plain":["0    2.160420\n","1    1.834839\n","2    1.901266\n","3    1.678495\n","4    1.371329\n","5    0.808950\n","6    0.556563\n","7    0.550500\n","8    0.551944\n","9    0.387016\n","Name: AVGYearlyClose, dtype: float32"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXoRoOOnhILN","executionInfo":{"status":"ok","timestamp":1634445108793,"user_tz":300,"elapsed":201,"user":{"displayName":"Brian Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06839045571344353225"}},"outputId":"7fd0a01f-d1ed-44ec-cb39-c8e83ea1b219"},"source":["for row in x_test:\n","  print(row)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["[2010, 8.01928755952381, 599305266.6666666, 31540.789949999995, 1197.55244, 50.73382000000001, 1051955.22124, 45518.90000000001, 3881.17444, 6816.04091, 2062.7582199999997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 281.6120000000001, 5329.600460000001, 2132.82244, 1290.19229, 4454.30649, 592.17222, 17322148.694, 2745.95467, 12500051.861, 12103.90253, 6237963.036, 3265.41101, 3367470.0, 0.0, 2140800.0, 0.0, 7704390.0, 2993520.0, 2741480.0, 267820.0, -750161.84094, 5448.84511, 8487571.0, 1638361.0, 438636.0, 66948.0, 286707.0, 4628.5, 933.1000000000003, 40999.09]\n","[2011, 11.233943111111122, 492298966.6666667, 32623.58808, 1204.93053, 51.53446, 1030683.5477100001, 42631.40000000001, 1996.8036700000002, 11002.99, 1984.4244800000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 283.72898, 5393.33426, 2161.44352, 1223.49419, 4450.438270000001, 570.2132899999999, 18482760.233, 2861.60107, 12462482.511, 11803.647130000001, 6367642.823999999, 3275.2539699999998, 3421190.0, 0.0, 2221570.0, 0.0, 7807040.0, 3042050.0, 2834570.0, 270990.0, -706229.78238, 5500.425719999999, 8836135.0, 1682596.0, 486531.0, 64153.0, 294212.0, 2901.1, -930.0999999999998, 40959.509999999995]\n","[2012, 17.821248772000015, 527856817.6, 33137.912710000004, 1284.2095399999998, 56.47579, 1462487.10814, 43000.7, 2146.3132100000003, 11125.22137, 2068.0676000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 285.73058000000003, 5434.887710000001, 2153.46841, 1231.3683299999998, 4517.38433, 562.52752, 18757730.547, 2946.48229, 12702328.344999999, 11615.04236, 6474818.232999999, 3221.1704, 3439240.0, 0.0, 2231950.0, 0.0, 7869970.0, 3079330.0, 2847630.0, 272720.0, -485433.2065400001, 5387.917360000001, 9006384.0, 1712648.0, 512705.0, 64700.0, 279827.0, 2513.0, -746.4, 41796.49]\n","[2013, 14.916098527777777, 406434800.0, 33617.93995, 1187.9175900000002, 48.86467999999999, 1483747.89457, 32469.200000000004, 2036.9867199999999, 9346.02, 1707.61483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 285.08537, 5387.81372, 2133.7110300000004, 1236.5792900000001, 4578.803599999999, 564.09132, 18563775.64, 3000.7146599999996, 12789275.395999998, 11920.58338, 6581498.596999999, 3178.0390500000003, 3405660.0, 0.0, 2208840.0, 0.0, 7880460.0, 3117610.0, 2838990.0, 278740.0, -450855.0172900001, 5269.39485, 9038132.0, 1745172.0, 547286.0, 68253.0, 288847.0, 1448.3, 0.0, 32029.76]\n","[2014, 20.875553535714282, 252610922.2222222, 33994.01229, 1142.35457, 45.44073999999999, 1654580.10451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 271.77444, 5422.20623, 2151.24798, 1209.5783, 4590.30469, 525.85375, 18539358.375, 2980.76939, 13004932.768, 12075.32241, 6641784.077, 3239.9028, 3427420.0, 0.0, 2234500.0, 0.0, 7957650.0, 3144320.0, 2881840.0, 281810.0, -611613.6637300001, 5074.01396, 9124436.0, 1755702.0, 562007.0, 67598.0, 292719.0, 293.9, 155.5, 6472.5599999999995]\n","[2015, 27.624358686507946, 207397617.46031746, 33900.84306, 885.5033000000001, 44.11973, 1080436.1716000002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.08118999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 14208994.276, 2928.33695, 10048951.458, 11753.38222, 6572558.450999999, 3247.0509700000002, 3442060.0, 0.0, 2241760.0, 0.0, 8021410.0, 3165590.0, 2904970.0, 286110.0, -638109.59637, 5423.12491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[2016, 24.571229154761898, 153690123.80952382, 33918.094509999995, 879.04897, 43.47726999999999, 802186.8704599999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2321.24625, 969.98839, 3241.37, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13788187.691, 2914.5731400000004, 10053117.170000002, 11540.360419999999, 6733734.102, 3261.58292, 3465770.0, 0.0, 2263530.0, 0.0, 8068580.0, 3173140.0, 2934600.0, 286950.0, -686834.7648, 5163.66892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[2017, 36.03107938247012, 108538270.91633466, 34349.79994, 872.4342899999999, 42.94906999999999, 730680.2342399999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2433.2581299999997, 1180.91635, 3255.15513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3505600.0, 0.0, 2306980.0, 0.0, 8137390.0, 3180470.0, 2986520.0, 288710.0, 0.0, 5186.621590000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[2018, 45.93522490438249, 136080258.16733068, 35196.13999, 886.32969, 43.961240000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 4518.0, 7558.0, 3360.0, 16527.0, 2433.2581299999997, 1294.3414400000001, 3255.15513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3513570.0, 0.0, 2296270.0, 0.0, 8174420.0, 3187680.0, 2984340.0, 290360.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[2019, 51.39953258730161, 112122788.8888889, 35519.16778999999, 886.7522700000001, 44.288410000000006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}]}]}